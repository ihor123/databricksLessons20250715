# Databricks notebook source
#dapiaa8531cfcdddc4dbddabeb1c7d8c1927

joined_df = spark.sql("""
SELECT /*+ BROADCAST(stores), BROADCAST(customers), BROADCAST(countries) */
       transactions.id,
       amount,
       countries.name AS country_name,
       employees,
       stores.name AS store_name,
       MAX(cc.name) AS max_customer_name,
       MAX(cc.customer_band) AS max_customer_band
FROM transactions AS transactions
LEFT JOIN stores
    ON transactions.store_id = stores.id
LEFT JOIN countries
    ON transactions.country_id = countries.id
LEFT JOIN customers c1
    ON transactions.customer_id = c1.id
LEFT JOIN customers cc
    ON c1.customer_master_id = cc.id
WHERE
      transactions.store_id between 10 and 20
  AND stores.employees > 10
  AND stores.employees <= 35
  AND c1.customer_band BETWEEN 15 AND 65
GROUP BY transactions.id,
         amount,
         countries.name,
         employees,
         stores.name
""")

joined_df.write.mode("overwrite").option("mergeSchema", "true").saveAsTable("transactioned_countries22")
