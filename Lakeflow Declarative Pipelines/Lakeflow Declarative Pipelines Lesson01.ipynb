{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7868175-283a-4426-9a8e-8f5a6c78a51d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0e49d0c5-e471-4886-9f1b-b2f8495e4f35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(DA.paths.working_dir)\n",
    "\n",
    "\n",
    "#select * from json.'{DA.paths.working_dir}/orders'\n",
    "#dbfs:/Volumes/workspace/ops/volumes/orders\n",
    "          \n",
    "spark.sql(f'''\n",
    "        select * \n",
    "        from json.`{DA.paths.working_dir}/orders`\n",
    "    ''').display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4205052-8c8e-4983-9a23-ff60b6384539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "create or replace table default.orders_bronze\n",
    "as\n",
    "select\n",
    "*,\n",
    "current_timestamp() as processing_time,\n",
    "_metadata.file_name as source_file\n",
    "from read_files(\n",
    "  \"dbfs:/Volumes/workspace/ops/volumes\" || \"/orders\",\n",
    "  format => \"json\"\n",
    ");\n",
    "\n",
    "create or replace table default.orders_silver\n",
    "as\n",
    "select\n",
    "order_id,\n",
    "timestamp(ordertimestamp) as order_timestamp,\n",
    "customer_id,\n",
    "source_file\n",
    "from default.orders_bronze;\n",
    "\n",
    "create or replace view default.orders_by_date_vw\n",
    "as\n",
    "select\n",
    "  date(order_timestamp) as order_date,\n",
    "  count(*) total_daily_orders\n",
    "from default.orders_silver\n",
    "group by date(order_timestamp);\n",
    "\n",
    "\n",
    "select * from default.orders_bronze;\n",
    "select * from default.orders_silver;\n",
    "select * from default.orders_by_date_vw;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7380199206076094,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Lakeflow Declarative Pipelines Lesson01",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
