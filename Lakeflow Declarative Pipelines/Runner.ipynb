{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "124c19e1-36b4-474f-ba47-1d5f3cb39c27",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"name\":257},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1756394705237}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "--DESCRIBE CATALOG workspace;\n",
    "--show tables in default  like  'transactions';\n",
    "\n",
    "--select * from information_schema.tables where table_name like 'transactions'\n",
    "\n",
    "--DESCRIBE EXTENDED workspace.default.transactions;\n",
    "\n",
    "/*\n",
    "select\n",
    "input_file_name,\n",
    "*\n",
    "from transactions\n",
    "limit 10;\n",
    "*/\n",
    "\n",
    "--DESCRIBE DETAIL transactions;\n",
    "\n",
    "--SHOW PARTITIONS transactions;\n",
    "\n",
    "--LIST '/user/hive/workspace';\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4bdc7af-c81b-440c-b4e6-40d450efd445",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#dbutils.fs.ls(\"/user/hive/warehouse/your_table_name.db/your_table_name\")\n",
    "#dbutils.fs.ls(\"/user/hive/workspace/default\")\n",
    "\n",
    "#ls \"/user/hive/workspace/default\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8d9d144-5d76-4cce-b546-111c9833464c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "\n",
    "databricks -v\n",
    "pwd\n",
    "ls\n",
    "databricks catalogs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe28cb22-09e9-49a7-9418-45761c2fd625",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, lit, year, month, dayofmonth, round, rand, col, from_unixtime\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import StringType, TimestampType, BooleanType, StructType, StructField, DoubleType, LongType\n",
    "\n",
    "\n",
    "class hp:\n",
    "    catalogue = \"workspace\"\n",
    "    database = \"default\"\n",
    "    display_target = \"development\"\n",
    "\n",
    "    def setup(self, catalogue = \"workspace\", database = \"default\", display_target = \"development\"):\n",
    "        s = None\n",
    "        try:\n",
    "            s = dbutils.widgets.get('catalogue_bronze_name')\n",
    "        except:\n",
    "            print('No catalogue_bronze_name parameter was found')\n",
    "            pass\n",
    "        if s is not None:\n",
    "            self.catalogue = s\n",
    "        s = None\n",
    "        try:\n",
    "            s = dbutils.widgets.get('database_bronze_name')\n",
    "        except:\n",
    "            print('No database_bronze_name parameter was found')\n",
    "            pass\n",
    "        if s is not None:\n",
    "            self.database = s\n",
    "        s = None\n",
    "        try:\n",
    "            s = dbutils.widgets.get('display_target')\n",
    "        except:\n",
    "            print('No display_target parameter was found')\n",
    "            pass\n",
    "        if s is not None:\n",
    "            self.display_target = s\n",
    "        s = None\n",
    "\n",
    "\n",
    "        if catalogue is not None:\n",
    "            self.catalogue = catalogue\n",
    "        if database is not None:\n",
    "            self.database = database\n",
    "        if display_target is not None:\n",
    "            self.display_target = display_target\n",
    "\n",
    "\n",
    "        spark.sql(f'USE CATALOG {self.catalogue}')\n",
    "        spark.sql(f'USE DATABASE {self.database}')\n",
    "\n",
    "\n",
    "        #spark.sql(\"DROP VARIABLE IF EXISTS catalogue_bronze_name\")\n",
    "        #spark.sql(\"DROP VARIABLE IF EXISTS database_bronze_name\")\n",
    "        #spark.sql(\"DROP VARIABLE IF EXISTS display_target\")\n",
    "        #spark.sql(\"DECLARE VARIABLE catalogue_bronze_name STRING\")\n",
    "        #spark.sql(\"DECLARE VARIABLE database_bronze_name STRING\")\n",
    "        #spark.sql(\"DECLARE VARIABLE display_target STRING\")\n",
    "        \n",
    "        spark.sql(\"drop temporary variable if exists catalogue_bronze_name;\")\n",
    "        spark.sql(\"declare variable catalogue_bronze_name string;\")\n",
    "        spark.sql(f\"set variable catalogue_bronze_name='{self.catalogue}';\")          \n",
    "\n",
    "        spark.sql(\"drop temporary variable if exists database_bronze_name;\")\n",
    "        spark.sql(\"declare variable database_bronze_name string;\")\n",
    "        spark.sql(f\"set variable database_bronze_name='{self.database}';\")          \n",
    "\n",
    "        spark.sql(\"drop temporary variable if exists display_target;\")\n",
    "        spark.sql(\"declare variable display_target string;\")\n",
    "        spark.sql(f\"set variable display_target='{self.display_target}';\")          \n",
    "\n",
    "\n",
    "    def __init__(self, catalogue = None, database = None, display_target = None):\n",
    "        self.setup(catalogue = catalogue, database = database, display_target = display_target)\n",
    "\n",
    "        pass\n",
    "\n",
    "    def add_standard_columns(self, df,createdBy=None,modifiedBy=None):\n",
    "        df = df.withColumn('timestamp', current_timestamp())\n",
    "\n",
    "        if modifiedBy is not None:\n",
    "            df = df.withColumn('modifiedOn', current_timestamp().cast(TimestampType()))\n",
    "            df = df.withColumn('modifiedBy', lit(modifiedBy).cast(StringType()))\n",
    "        else:\n",
    "            df = df.withColumn('modifiedOn', lit(None).cast(TimestampType()))\n",
    "            df = df.withColumn('modifiedBy', lit(None).cast(StringType()))\n",
    "        if createdBy is not None:\n",
    "            df = df.withColumn('createdOn', current_timestamp())\n",
    "            df = df.withColumn('createdBy', lit(createdBy).cast (StringType()))\n",
    "        else:\n",
    "            df = df.withColumn('createdOn', lit(None).cast(TimestampType()))\n",
    "            df = df.withColumn('createdBy', lit(None).cast (StringType()))\n",
    "        \n",
    "        df = df.withColumn('isCurrent', lit(True).cast(BooleanType()))\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def transactions_pt(self, df):\n",
    "        df = (\n",
    "          df\n",
    "            .withColumn('year', year(df['time']))\n",
    "            .withColumn('month', month(df['time']))\n",
    "            .withColumn('customer_partition', df['customer_id']%10)\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "chp = hp()\n",
    "#chp.setup(catalogue=\"ops\",database=\"etl\")\n",
    "\n",
    "# Example usage:\n",
    "# transformer = DataFrameTransformer(some_df)\n",
    "# transformed_df = transformer.add_timestamp_column()\n",
    "# display(transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d5f70fa-9047-4b24-8c31-8fbac1e83ad1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "ore"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "schema = StructType([\n",
    "    StructField('id', LongType(), False),\n",
    "    StructField('amount', DoubleType(), False),\n",
    "    StructField('country_id', LongType(), False),\n",
    "    StructField('store_id', LongType(), False),\n",
    "    StructField('customer_id', LongType(), False),\n",
    "    StructField('time', TimestampType(), False)\n",
    "])\n",
    "empty_df = spark.createDataFrame([], schema=schema)\n",
    "\n",
    "empty_df = chp.add_standard_columns(empty_df)\n",
    "\n",
    "empty_df = chp.transactions_pt(empty_df)\n",
    "\n",
    "#display(empty_df)\n",
    "\n",
    "#(\n",
    "#    empty_df.write.mode(\"overwrite\")\n",
    "#        .option(\"overwriteSchema\", \"true\")\n",
    "#        .partitionBy(\"year\",\"store_id\",\"customer_partition\")\n",
    "#        .saveAsTable(f\"{chp.catalogue}.{chp.database}.transactions\")\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4699b960-c85e-447a-b3b7-2d4d2f649b7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#150000000000\n",
    "\n",
    "i1=0\n",
    "step=50000000\n",
    "#imax=150000000000\n",
    "imax=1\n",
    "i=1\n",
    "\n",
    "while i1<imax:\n",
    "    i2=i1+step\n",
    "\n",
    "    print(\"Starting iteration i=\",i,\" i1=\",i1,\"i2=\",i2,\"imax=\",imax,\"step=\",step, \" current timestamp \",datetime.now())\n",
    "\n",
    "    df = (\n",
    "        spark\n",
    "            .range(i1,i2,1)#,32)\n",
    "            .select(\n",
    "                'id',\n",
    "                round(rand()*1000,2).alias('amount'),\n",
    "                (col('id')%10).alias('country_id'),\n",
    "                (col('id')%100).alias('store_id'),\n",
    "                round(rand()*100000000,0).cast(LongType()).alias('customer_id'),\n",
    "                from_unixtime(lit(1701692381+col('id'))).cast(TimestampType()).alias('time'),\n",
    "        \n",
    "            )\n",
    "    )\n",
    "\n",
    "    df1 = chp.add_standard_columns(df,'etl')\n",
    "    df2 = chp.add_standard_columns(df,'etl','mml2')\n",
    "\n",
    "    df1 = df1.union(df2)\n",
    "\n",
    "    df1 = chp.transactions_pt(df1)\n",
    "\n",
    "#display(df1)\n",
    "\n",
    "    (\n",
    "        df1.write.mode(\"append\")\n",
    "            .option(\"mergeSchema\", \"false\")\n",
    "            .partitionBy(\"year\",\"store_id\",\"customer_partition\")\n",
    "            .saveAsTable(f\"{chp.catalogue}.{chp.database}.transactions\")\n",
    "    )\n",
    "\n",
    "    print(\"Iteration i=\", \" is over\",i,\" i1=\",i1,\"i2=\",i2,\"imax=\",imax,\"step=\",step, \" current timestamp \",datetime.now())\n",
    "\n",
    "    i=i+1\n",
    "    i1=i1+step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b111c875-4319-4cfc-b213-1af7e6d6f648",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select count(*) as rccount from transactions"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7221713038488772,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Runner",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
